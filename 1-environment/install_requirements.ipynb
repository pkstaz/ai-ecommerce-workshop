{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements - OpenShift AI Workshop\n",
    "## ðŸ“¦ Setting Up Python Dependencies\n",
    "\n",
    "---\n",
    "\n",
    "**Module:** 1 - Environment Setup  \n",
    "**Objective:** Install all required Python libraries for the AI e-commerce workshop  \n",
    "**Estimated Time:** 10-15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will install all the necessary Python packages for:\n",
    "- ðŸ¤– Machine Learning (scikit-learn, onnx)\n",
    "- ðŸ§  Large Language Models (langchain)\n",
    "- ðŸ“Š Data Analysis (pandas, numpy, plotly)\n",
    "- ðŸŒ Web Interfaces (gradio)\n",
    "- ðŸ“ˆ Monitoring (prometheus-client)\n",
    "- ðŸ”§ Utilities (requests)\n",
    "\n",
    "---\n",
    "\n",
    "pip install git+https://github.com/onnx/sklearn-onnx.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Step 1: Check Current Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ðŸ” Environment Information\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ðŸ Python Version: {sys.version}\")\n",
    "print(f\"ðŸ’» Platform: {platform.platform()}\")\n",
    "print(f\"ðŸ“ Python Path: {sys.executable}\")\n",
    "print(f\"ðŸ“¦ Pip Version: {subprocess.check_output([sys.executable, '-m', 'pip', '--version']).decode().strip()}\")\n",
    "print(\"\\nâœ… Environment check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 2: Define Core Package Requirements\n",
    "\n",
    "We'll focus on essential packages first, avoiding those that commonly cause conflicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core essential packages for the workshop\n",
    "CORE_PACKAGES = [\n",
    "    # Machine Learning Core\n",
    "    \"scikit-learn>=1.3.0\",\n",
    "    \"numpy>=1.24.0\",\n",
    "    \"pandas>=2.0.0\",\n",
    "    \"scipy>=1.11.0\",\n",
    "    \n",
    "    # Model Export\n",
    "    \"onnx>=1.14.0\",\n",
    "    \"skl2onnx>=1.15.0\",\n",
    "    \"onnxruntime>=1.16.0\",\n",
    "    \n",
    "    # LLM - Basic\n",
    "    \"langchain>=0.1.0\",\n",
    "    \"langchain-community>=0.0.13\",  # Additional langchain features\n",
    "    \"openai>=1.3.0\",\n",
    "    \n",
    "    # Visualization\n",
    "    \"matplotlib>=3.7.0\",\n",
    "    \"plotly>=5.17.0\",\n",
    "    \"seaborn>=0.12.0\",\n",
    "    \n",
    "    # Web Interface\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"flask>=2.3.0\",\n",
    "    \n",
    "    # Monitoring\n",
    "    \"prometheus-client>=0.19.0\",\n",
    "    \"psutil>=5.9.0\",\n",
    "    \n",
    "    # Utilities\n",
    "    \"requests>=2.31.0\",\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"pyyaml>=6.0.0\",\n",
    "    \"tqdm>=4.66.0\",\n",
    "    \n",
    "    # Development\n",
    "    \"ipywidgets>=8.0.0\",\n",
    "]\n",
    "\n",
    "# Optional packages that may cause conflicts\n",
    "OPTIONAL_PACKAGES = [\n",
    "    \"streamlit>=1.28.0\",       # Tornado conflicts\n",
    "    \"transformers>=4.36.0\",    # Heavy dependencies\n",
    "    \"torch>=2.1.0\",            # Very large\n",
    "    \"openvino>=2023.2.0\",      # Platform specific \n",
    "]\n",
    "\n",
    "print(\"ðŸ“‹ Package Installation Plan\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸŽ¯ Core packages to install: {len(CORE_PACKAGES)}\")\n",
    "print(f\"âšª Optional packages: {len(OPTIONAL_PACKAGES)}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Core Packages:\")\n",
    "for package in CORE_PACKAGES:\n",
    "    print(f\"  â€¢ {package}\")\n",
    "\n",
    "print(\"\\nâšª Optional Packages (install manually if needed):\")\n",
    "for package in OPTIONAL_PACKAGES:\n",
    "    print(f\"  â€¢ {package}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ Step 3: Simple Installation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_package(package_spec):\n",
    "    \"\"\"Install a package using pip - simple and reliable\"\"\"\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", package_spec]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        return True, \"Success\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return False, e.stderr\n",
    "\n",
    "def get_package_name(package_spec):\n",
    "    \"\"\"Extract package name from specification\"\"\"\n",
    "    # Handle package>=version format\n",
    "    for separator in ['>=', '==', '<=', '>', '<', '!=']:\n",
    "        if separator in package_spec:\n",
    "            return package_spec.split(separator)[0]\n",
    "    return package_spec\n",
    "\n",
    "def check_package_importable(package_name):\n",
    "    \"\"\"Check if package can be imported (simple test)\"\"\"\n",
    "    try:\n",
    "        # Try common import name variations\n",
    "        import_names = [\n",
    "            package_name,\n",
    "            package_name.replace('-', '_'),\n",
    "            package_name.replace('_', '-'),\n",
    "        ]\n",
    "        \n",
    "        for name in import_names:\n",
    "            try:\n",
    "                __import__(name)\n",
    "                return True\n",
    "            except ImportError:\n",
    "                continue\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print(\"ðŸ”§ Installation functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 4: Install Core Packages\n",
    "\n",
    "Installing essential packages one by one with clear progress reporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸš€ Installing core packages...\\n\")\n",
    "\n",
    "successful_installs = []\n",
    "failed_installs = []\n",
    "already_available = []\n",
    "\n",
    "for i, package_spec in enumerate(CORE_PACKAGES, 1):\n",
    "    package_name = get_package_name(package_spec)\n",
    "    \n",
    "    print(f\"[{i:2d}/{len(CORE_PACKAGES)}] {package_name}...\", end=\" \")\n",
    "    \n",
    "    # Quick check if already importable\n",
    "    if check_package_importable(package_name):\n",
    "        print(\"âœ… Already available\")\n",
    "        already_available.append(package_name)\n",
    "        continue\n",
    "    \n",
    "    # Try to install\n",
    "    success, message = install_package(package_spec)\n",
    "    \n",
    "    if success:\n",
    "        print(\"âœ… Installed\")\n",
    "        successful_installs.append(package_name)\n",
    "    else:\n",
    "        print(\"âŒ Failed\")\n",
    "        failed_installs.append((package_name, message[:100]))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ðŸ“Š Installation Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"âœ… Already available: {len(already_available)}\")\n",
    "print(f\"âœ… Successfully installed: {len(successful_installs)}\")\n",
    "print(f\"âŒ Failed installations: {len(failed_installs)}\")\n",
    "print(f\"ðŸ“Š Total ready: {len(already_available) + len(successful_installs)}/{len(CORE_PACKAGES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ©º Step 5: Handle Failed Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if failed_installs:\n",
    "    print(\"ðŸ”§ Attempting to fix failed installations...\\n\")\n",
    "    \n",
    "    retry_success = []\n",
    "    permanent_failures = []\n",
    "    \n",
    "    for package_name, error in failed_installs:\n",
    "        print(f\"ðŸ©º Retrying {package_name}...\")\n",
    "        \n",
    "        # Try different installation strategies\n",
    "        strategies = [\n",
    "            [\"--no-cache-dir\"],\n",
    "            [\"--user\"],\n",
    "            [\"--force-reinstall\", \"--no-deps\"],\n",
    "        ]\n",
    "        \n",
    "        success = False\n",
    "        for strategy in strategies:\n",
    "            cmd = [sys.executable, \"-m\", \"pip\", \"install\"] + strategy + [package_name]\n",
    "            try:\n",
    "                subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "                print(f\"  âœ… Fixed with {' '.join(strategy)}\")\n",
    "                retry_success.append(package_name)\n",
    "                success = True\n",
    "                break\n",
    "            except subprocess.CalledProcessError:\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"  âŒ Still failing: {package_name}\")\n",
    "            permanent_failures.append(package_name)\n",
    "    \n",
    "    print(f\"\\nðŸ”§ Retry Results:\")\n",
    "    print(f\"  âœ… Fixed: {len(retry_success)}\")\n",
    "    print(f\"  âŒ Still failing: {len(permanent_failures)}\")\n",
    "    \n",
    "    if permanent_failures:\n",
    "        print(f\"\\nâš ï¸ Permanently failed packages: {', '.join(permanent_failures)}\")\n",
    "        print(\"   These packages can be installed manually later if needed.\")\n",
    "\n",
    "else:\n",
    "    print(\"ðŸŽ‰ No failed installations to handle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Step 6: Verify Core Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ” Testing critical functionality...\\n\")\n",
    "\n",
    "# Test critical imports\n",
    "critical_tests = {\n",
    "    \"Machine Learning\": [\n",
    "        (\"import sklearn\", \"scikit-learn\"),\n",
    "        (\"import pandas as pd\", \"pandas\"),\n",
    "        (\"import numpy as np\", \"numpy\"),\n",
    "    ],\n",
    "    \"Model Export\": [\n",
    "        (\"import onnx\", \"ONNX\"),\n",
    "        (\"import skl2onnx\", \"scikit-learn to ONNX\"),\n",
    "    ],\n",
    "    \"LLM Support\": [\n",
    "        (\"import langchain\", \"LangChain\"),\n",
    "        (\"import openai\", \"OpenAI client\"),\n",
    "    ],\n",
    "    \"Visualization\": [\n",
    "        (\"import matplotlib.pyplot as plt\", \"matplotlib\"),\n",
    "        (\"import plotly.graph_objects as go\", \"plotly\"),\n",
    "    ],\n",
    "    \"Web Interface\": [\n",
    "        (\"import gradio as gr\", \"Gradio\"),\n",
    "        (\"import flask\", \"Flask\"),\n",
    "    ],\n",
    "    \"Utilities\": [\n",
    "        (\"import requests\", \"HTTP requests\"),\n",
    "        (\"import yaml\", \"YAML processing\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "total_tests = sum(len(tests) for tests in critical_tests.values())\n",
    "passed_tests = 0\n",
    "failed_tests = []\n",
    "\n",
    "for category, tests in critical_tests.items():\n",
    "    print(f\"ðŸ§ª {category}:\")\n",
    "    for test_code, description in tests:\n",
    "        try:\n",
    "            exec(test_code)\n",
    "            print(f\"  âœ… {description}\")\n",
    "            passed_tests += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {description}: {str(e)[:50]}...\")\n",
    "            failed_tests.append(description)\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸ§ª Test Results: {passed_tests}/{total_tests} passed\")\n",
    "\n",
    "if passed_tests >= total_tests * 0.8:  # 80% success rate\n",
    "    print(\"ðŸŸ¢ EXCELLENT: Core functionality is ready!\")\n",
    "elif passed_tests >= total_tests * 0.6:  # 60% success rate\n",
    "    print(\"ðŸŸ¡ GOOD: Most functionality available, some optional features missing\")\n",
    "else:\n",
    "    print(\"ðŸ”´ NEEDS ATTENTION: Many core features are missing\")\n",
    "\n",
    "if failed_tests:\n",
    "    print(f\"\\nâš ï¸ Failed imports: {', '.join(failed_tests)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 7: Quick ML Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ¤– Testing ML pipeline functionality...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test basic ML workflow\n",
    "    import sklearn\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"ðŸ“Š Creating test dataset...\")\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"ðŸŒ² Training Random Forest...\")\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f\"âœ… Model accuracy: {score:.3f}\")\n",
    "    \n",
    "    # Test ONNX export if available\n",
    "    try:\n",
    "        import onnx\n",
    "        import skl2onnx\n",
    "        from skl2onnx import convert_sklearn\n",
    "        from skl2onnx.common.data_types import FloatTensorType\n",
    "        \n",
    "        print(\"ðŸ”„ Testing ONNX export...\")\n",
    "        initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "        onnx_model = convert_sklearn(clf, initial_types=initial_type)\n",
    "        print(\"âœ… ONNX export successful\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ONNX export failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    print(\"\\nðŸŽ‰ ML pipeline test: SUCCESS\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ML pipeline test failed: {str(e)}\")\n",
    "    print(\"   This indicates core ML packages may not be properly installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 8: Environment Health Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ðŸ“‹ Generating Environment Health Report...\\n\")\n",
    "\n",
    "# System information\n",
    "try:\n",
    "    import psutil\n",
    "    memory_gb = psutil.virtual_memory().total / (1024**3)\n",
    "    available_gb = psutil.virtual_memory().available / (1024**3)\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    system_info = {\n",
    "        \"memory_total_gb\": round(memory_gb, 2),\n",
    "        \"memory_available_gb\": round(available_gb, 2),\n",
    "        \"cpu_cores\": cpu_count\n",
    "    }\n",
    "except ImportError:\n",
    "    system_info = {\"status\": \"psutil not available\"}\n",
    "\n",
    "# Create comprehensive report\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"python_version\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "    \"platform\": platform.platform(),\n",
    "    \"system_info\": system_info,\n",
    "    \"installation_summary\": {\n",
    "        \"total_packages\": len(CORE_PACKAGES),\n",
    "        \"already_available\": len(already_available),\n",
    "        \"newly_installed\": len(successful_installs),\n",
    "        \"failed\": len(failed_installs),\n",
    "        \"success_rate\": f\"{((len(already_available) + len(successful_installs)) / len(CORE_PACKAGES) * 100):.1f}%\"\n",
    "    },\n",
    "    \"functionality_tests\": {\n",
    "        \"total_tests\": total_tests,\n",
    "        \"passed_tests\": passed_tests,\n",
    "        \"success_rate\": f\"{(passed_tests / total_tests * 100):.1f}%\" if total_tests > 0 else \"0%\"\n",
    "    },\n",
    "    \"ready_for_workshop\": passed_tests >= total_tests * 0.8 and len(failed_installs) <= 2\n",
    "}\n",
    "\n",
    "# Save report\n",
    "with open(\"workshop_environment_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# Display summary\n",
    "print(\"ðŸŽ¯ WORKSHOP READINESS ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸ“… Assessment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ðŸ Python: {report['python_version']}\")\n",
    "\n",
    "if 'memory_total_gb' in system_info:\n",
    "    print(f\"ðŸ’¾ Memory: {system_info['memory_available_gb']:.1f}GB available / {system_info['memory_total_gb']:.1f}GB total\")\n",
    "    print(f\"ðŸ–¥ï¸ CPU: {system_info['cpu_cores']} cores\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Package Installation: {report['installation_summary']['success_rate']}\")\n",
    "print(f\"ðŸ§ª Functionality Tests: {report['functionality_tests']['success_rate']}\")\n",
    "\n",
    "if report['ready_for_workshop']:\n",
    "    print(\"\\nðŸŸ¢ STATUS: READY FOR WORKSHOP! ðŸŽ‰\")\n",
    "    print(\"âœ… Your environment is properly configured\")\n",
    "    print(\"âœ… Core ML functionality verified\")\n",
    "    print(\"âœ… You can proceed to Module 2: Predictive Model\")\n",
    "else:\n",
    "    print(\"\\nðŸŸ¡ STATUS: PARTIALLY READY\")\n",
    "    print(\"âš ï¸ Some features may be limited\")\n",
    "    print(\"ðŸ’¡ Consider installing missing packages manually\")\n",
    "    print(\"ðŸ“ Check the failed tests above for details\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Full report saved to: workshop_environment_report.json\")\n",
    "\n",
    "# Optional packages reminder\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ðŸ’¡ OPTIONAL PACKAGES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"For advanced features, you can install these manually:\")\n",
    "for package in OPTIONAL_PACKAGES:\n",
    "    print(f\"  pip install {package}\")\n",
    "\n",
    "print(\"\\nðŸš€ Ready for Module 2: Predictive Model Development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Next Steps\n",
    "\n",
    "Your Python environment setup is complete! Here's what to do next:\n",
    "\n",
    "### âœ… If Status is \"READY FOR WORKSHOP\" (Green):\n",
    "1. **Continue to Module 2:** Start with predictive model development\n",
    "2. **Run verification notebook:** `1-environment/verify_environment.ipynb`\n",
    "3. **Download datasets:** `1-environment/download_datasets.ipynb`\n",
    "\n",
    "### âš ï¸ If Status is \"PARTIALLY READY\" (Yellow):\n",
    "1. **Review failed packages:** Check which specific features are missing\n",
    "2. **Install manually:** Use the pip commands shown above for missing packages\n",
    "3. **Restart kernel:** After manual installations, restart and re-run verification\n",
    "4. **Continue anyway:** Most workshop features should still work\n",
    "\n",
    "### ðŸ”§ Manual Installation Commands:\n",
    "```bash\n",
    "# If specific packages failed, try:\n",
    "pip install --no-cache-dir package_name\n",
    "pip install --user package_name\n",
    "pip install --force-reinstall package_name\n",
    "\n",
    "# For optional advanced features:\n",
    "pip install streamlit>=1.28.0\n",
    "pip install transformers>=4.36.0\n",
    "pip install torch>=2.1.0\n",
    "```\n",
    "\n",
    "### ðŸ“š What You Now Have:\n",
    "- âœ… **Core ML:** scikit-learn, pandas, numpy\n",
    "- âœ… **Model Export:** ONNX conversion capabilities\n",
    "- âœ… **LLM Integration:** LangChain framework\n",
    "- âœ… **Visualization:** matplotlib, plotly, seaborn\n",
    "- âœ… **Web Interface:** Gradio for dashboards\n",
    "- âœ… **Monitoring:** System metrics collection\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for the next step?** ðŸš€  \n",
    "**Next:** [Module 2 - Predictive Model Development](../02-predictive-model.md)\n",
    "\n",
    "---\n",
    "\n",
    "*Workshop Progress: Module 1 Complete âœ…*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
