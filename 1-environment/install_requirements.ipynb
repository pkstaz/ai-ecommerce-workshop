{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Requirements - OpenShift AI Workshop\n",
    "## 📦 Setting Up Python Dependencies\n",
    "\n",
    "---\n",
    "\n",
    "**Module:** 1 - Environment Setup  \n",
    "**Objective:** Install all required Python libraries for the AI e-commerce workshop  \n",
    "**Estimated Time:** 10-15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will install all the necessary Python packages for:\n",
    "- 🤖 Machine Learning (scikit-learn, onnx)\n",
    "- 🧠 Large Language Models (langchain)\n",
    "- 📊 Data Analysis (pandas, numpy, plotly)\n",
    "- 🌐 Web Interfaces (gradio)\n",
    "- 📈 Monitoring (prometheus-client)\n",
    "- 🔧 Utilities (requests)\n",
    "\n",
    "---\n",
    "\n",
    "pip install git+https://github.com/onnx/sklearn-onnx.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 1: Check Current Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🔍 Environment Information\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📅 Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🐍 Python Version: {sys.version}\")\n",
    "print(f\"💻 Platform: {platform.platform()}\")\n",
    "print(f\"📁 Python Path: {sys.executable}\")\n",
    "print(f\"📦 Pip Version: {subprocess.check_output([sys.executable, '-m', 'pip', '--version']).decode().strip()}\")\n",
    "print(\"\\n✅ Environment check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Step 2: Define Core Package Requirements\n",
    "\n",
    "We'll focus on essential packages first, avoiding those that commonly cause conflicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core essential packages for the workshop\n",
    "CORE_PACKAGES = [\n",
    "    # Machine Learning Core\n",
    "    \"scikit-learn>=1.3.0\",\n",
    "    \"numpy>=1.24.0\",\n",
    "    \"pandas>=2.0.0\",\n",
    "    \"scipy>=1.11.0\",\n",
    "    \n",
    "    # Model Export\n",
    "    \"onnx>=1.14.0\",\n",
    "    \"skl2onnx>=1.15.0\",\n",
    "    \"onnxruntime>=1.16.0\",\n",
    "    \n",
    "    # LLM - Basic\n",
    "    \"langchain>=0.1.0\",\n",
    "    \"langchain-community>=0.0.13\",  # Additional langchain features\n",
    "    \"openai>=1.3.0\",\n",
    "    \n",
    "    # Visualization\n",
    "    \"matplotlib>=3.7.0\",\n",
    "    \"plotly>=5.17.0\",\n",
    "    \"seaborn>=0.12.0\",\n",
    "    \n",
    "    # Web Interface\n",
    "    \"gradio>=4.0.0\",\n",
    "    \"flask>=2.3.0\",\n",
    "    \n",
    "    # Monitoring\n",
    "    \"prometheus-client>=0.19.0\",\n",
    "    \"psutil>=5.9.0\",\n",
    "    \n",
    "    # Utilities\n",
    "    \"requests>=2.31.0\",\n",
    "    \"python-dotenv>=1.0.0\",\n",
    "    \"pyyaml>=6.0.0\",\n",
    "    \"tqdm>=4.66.0\",\n",
    "    \n",
    "    # Development\n",
    "    \"ipywidgets>=8.0.0\",\n",
    "]\n",
    "\n",
    "# Optional packages that may cause conflicts\n",
    "OPTIONAL_PACKAGES = [\n",
    "    \"streamlit>=1.28.0\",       # Tornado conflicts\n",
    "    \"transformers>=4.36.0\",    # Heavy dependencies\n",
    "    \"torch>=2.1.0\",            # Very large\n",
    "    \"openvino>=2023.2.0\",      # Platform specific \n",
    "]\n",
    "\n",
    "print(\"📋 Package Installation Plan\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 Core packages to install: {len(CORE_PACKAGES)}\")\n",
    "print(f\"⚪ Optional packages: {len(OPTIONAL_PACKAGES)}\")\n",
    "\n",
    "print(\"\\n🎯 Core Packages:\")\n",
    "for package in CORE_PACKAGES:\n",
    "    print(f\"  • {package}\")\n",
    "\n",
    "print(\"\\n⚪ Optional Packages (install manually if needed):\")\n",
    "for package in OPTIONAL_PACKAGES:\n",
    "    print(f\"  • {package}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Step 3: Simple Installation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_package(package_spec):\n",
    "    \"\"\"Install a package using pip - simple and reliable\"\"\"\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", package_spec]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "        return True, \"Success\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return False, e.stderr\n",
    "\n",
    "def get_package_name(package_spec):\n",
    "    \"\"\"Extract package name from specification\"\"\"\n",
    "    # Handle package>=version format\n",
    "    for separator in ['>=', '==', '<=', '>', '<', '!=']:\n",
    "        if separator in package_spec:\n",
    "            return package_spec.split(separator)[0]\n",
    "    return package_spec\n",
    "\n",
    "def check_package_importable(package_name):\n",
    "    \"\"\"Check if package can be imported (simple test)\"\"\"\n",
    "    try:\n",
    "        # Try common import name variations\n",
    "        import_names = [\n",
    "            package_name,\n",
    "            package_name.replace('-', '_'),\n",
    "            package_name.replace('_', '-'),\n",
    "        ]\n",
    "        \n",
    "        for name in import_names:\n",
    "            try:\n",
    "                __import__(name)\n",
    "                return True\n",
    "            except ImportError:\n",
    "                continue\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "print(\"🔧 Installation functions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Step 4: Install Core Packages\n",
    "\n",
    "Installing essential packages one by one with clear progress reporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Installing core packages...\\n\")\n",
    "\n",
    "successful_installs = []\n",
    "failed_installs = []\n",
    "already_available = []\n",
    "\n",
    "for i, package_spec in enumerate(CORE_PACKAGES, 1):\n",
    "    package_name = get_package_name(package_spec)\n",
    "    \n",
    "    print(f\"[{i:2d}/{len(CORE_PACKAGES)}] {package_name}...\", end=\" \")\n",
    "    \n",
    "    # Quick check if already importable\n",
    "    if check_package_importable(package_name):\n",
    "        print(\"✅ Already available\")\n",
    "        already_available.append(package_name)\n",
    "        continue\n",
    "    \n",
    "    # Try to install\n",
    "    success, message = install_package(package_spec)\n",
    "    \n",
    "    if success:\n",
    "        print(\"✅ Installed\")\n",
    "        successful_installs.append(package_name)\n",
    "    else:\n",
    "        print(\"❌ Failed\")\n",
    "        failed_installs.append((package_name, message[:100]))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📊 Installation Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"✅ Already available: {len(already_available)}\")\n",
    "print(f\"✅ Successfully installed: {len(successful_installs)}\")\n",
    "print(f\"❌ Failed installations: {len(failed_installs)}\")\n",
    "print(f\"📊 Total ready: {len(already_available) + len(successful_installs)}/{len(CORE_PACKAGES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🩺 Step 5: Handle Failed Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if failed_installs:\n",
    "    print(\"🔧 Attempting to fix failed installations...\\n\")\n",
    "    \n",
    "    retry_success = []\n",
    "    permanent_failures = []\n",
    "    \n",
    "    for package_name, error in failed_installs:\n",
    "        print(f\"🩺 Retrying {package_name}...\")\n",
    "        \n",
    "        # Try different installation strategies\n",
    "        strategies = [\n",
    "            [\"--no-cache-dir\"],\n",
    "            [\"--user\"],\n",
    "            [\"--force-reinstall\", \"--no-deps\"],\n",
    "        ]\n",
    "        \n",
    "        success = False\n",
    "        for strategy in strategies:\n",
    "            cmd = [sys.executable, \"-m\", \"pip\", \"install\"] + strategy + [package_name]\n",
    "            try:\n",
    "                subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "                print(f\"  ✅ Fixed with {' '.join(strategy)}\")\n",
    "                retry_success.append(package_name)\n",
    "                success = True\n",
    "                break\n",
    "            except subprocess.CalledProcessError:\n",
    "                continue\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"  ❌ Still failing: {package_name}\")\n",
    "            permanent_failures.append(package_name)\n",
    "    \n",
    "    print(f\"\\n🔧 Retry Results:\")\n",
    "    print(f\"  ✅ Fixed: {len(retry_success)}\")\n",
    "    print(f\"  ❌ Still failing: {len(permanent_failures)}\")\n",
    "    \n",
    "    if permanent_failures:\n",
    "        print(f\"\\n⚠️ Permanently failed packages: {', '.join(permanent_failures)}\")\n",
    "        print(\"   These packages can be installed manually later if needed.\")\n",
    "\n",
    "else:\n",
    "    print(\"🎉 No failed installations to handle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Step 6: Verify Core Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Testing critical functionality...\\n\")\n",
    "\n",
    "# Test critical imports\n",
    "critical_tests = {\n",
    "    \"Machine Learning\": [\n",
    "        (\"import sklearn\", \"scikit-learn\"),\n",
    "        (\"import pandas as pd\", \"pandas\"),\n",
    "        (\"import numpy as np\", \"numpy\"),\n",
    "    ],\n",
    "    \"Model Export\": [\n",
    "        (\"import onnx\", \"ONNX\"),\n",
    "        (\"import skl2onnx\", \"scikit-learn to ONNX\"),\n",
    "    ],\n",
    "    \"LLM Support\": [\n",
    "        (\"import langchain\", \"LangChain\"),\n",
    "        (\"import openai\", \"OpenAI client\"),\n",
    "    ],\n",
    "    \"Visualization\": [\n",
    "        (\"import matplotlib.pyplot as plt\", \"matplotlib\"),\n",
    "        (\"import plotly.graph_objects as go\", \"plotly\"),\n",
    "    ],\n",
    "    \"Web Interface\": [\n",
    "        (\"import gradio as gr\", \"Gradio\"),\n",
    "        (\"import flask\", \"Flask\"),\n",
    "    ],\n",
    "    \"Utilities\": [\n",
    "        (\"import requests\", \"HTTP requests\"),\n",
    "        (\"import yaml\", \"YAML processing\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "total_tests = sum(len(tests) for tests in critical_tests.values())\n",
    "passed_tests = 0\n",
    "failed_tests = []\n",
    "\n",
    "for category, tests in critical_tests.items():\n",
    "    print(f\"🧪 {category}:\")\n",
    "    for test_code, description in tests:\n",
    "        try:\n",
    "            exec(test_code)\n",
    "            print(f\"  ✅ {description}\")\n",
    "            passed_tests += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ {description}: {str(e)[:50]}...\")\n",
    "            failed_tests.append(description)\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"🧪 Test Results: {passed_tests}/{total_tests} passed\")\n",
    "\n",
    "if passed_tests >= total_tests * 0.8:  # 80% success rate\n",
    "    print(\"🟢 EXCELLENT: Core functionality is ready!\")\n",
    "elif passed_tests >= total_tests * 0.6:  # 60% success rate\n",
    "    print(\"🟡 GOOD: Most functionality available, some optional features missing\")\n",
    "else:\n",
    "    print(\"🔴 NEEDS ATTENTION: Many core features are missing\")\n",
    "\n",
    "if failed_tests:\n",
    "    print(f\"\\n⚠️ Failed imports: {', '.join(failed_tests)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Step 7: Quick ML Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🤖 Testing ML pipeline functionality...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test basic ML workflow\n",
    "    import sklearn\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"📊 Creating test dataset...\")\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"🌲 Training Random Forest...\")\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f\"✅ Model accuracy: {score:.3f}\")\n",
    "    \n",
    "    # Test ONNX export if available\n",
    "    try:\n",
    "        import onnx\n",
    "        import skl2onnx\n",
    "        from skl2onnx import convert_sklearn\n",
    "        from skl2onnx.common.data_types import FloatTensorType\n",
    "        \n",
    "        print(\"🔄 Testing ONNX export...\")\n",
    "        initial_type = [('float_input', FloatTensorType([None, 10]))]\n",
    "        onnx_model = convert_sklearn(clf, initial_types=initial_type)\n",
    "        print(\"✅ ONNX export successful\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ONNX export failed: {str(e)[:50]}...\")\n",
    "    \n",
    "    print(\"\\n🎉 ML pipeline test: SUCCESS\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ ML pipeline test failed: {str(e)}\")\n",
    "    print(\"   This indicates core ML packages may not be properly installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Step 8: Environment Health Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"📋 Generating Environment Health Report...\\n\")\n",
    "\n",
    "# System information\n",
    "try:\n",
    "    import psutil\n",
    "    memory_gb = psutil.virtual_memory().total / (1024**3)\n",
    "    available_gb = psutil.virtual_memory().available / (1024**3)\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    system_info = {\n",
    "        \"memory_total_gb\": round(memory_gb, 2),\n",
    "        \"memory_available_gb\": round(available_gb, 2),\n",
    "        \"cpu_cores\": cpu_count\n",
    "    }\n",
    "except ImportError:\n",
    "    system_info = {\"status\": \"psutil not available\"}\n",
    "\n",
    "# Create comprehensive report\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"python_version\": f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\",\n",
    "    \"platform\": platform.platform(),\n",
    "    \"system_info\": system_info,\n",
    "    \"installation_summary\": {\n",
    "        \"total_packages\": len(CORE_PACKAGES),\n",
    "        \"already_available\": len(already_available),\n",
    "        \"newly_installed\": len(successful_installs),\n",
    "        \"failed\": len(failed_installs),\n",
    "        \"success_rate\": f\"{((len(already_available) + len(successful_installs)) / len(CORE_PACKAGES) * 100):.1f}%\"\n",
    "    },\n",
    "    \"functionality_tests\": {\n",
    "        \"total_tests\": total_tests,\n",
    "        \"passed_tests\": passed_tests,\n",
    "        \"success_rate\": f\"{(passed_tests / total_tests * 100):.1f}%\" if total_tests > 0 else \"0%\"\n",
    "    },\n",
    "    \"ready_for_workshop\": passed_tests >= total_tests * 0.8 and len(failed_installs) <= 2\n",
    "}\n",
    "\n",
    "# Save report\n",
    "with open(\"workshop_environment_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "# Display summary\n",
    "print(\"🎯 WORKSHOP READINESS ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"📅 Assessment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🐍 Python: {report['python_version']}\")\n",
    "\n",
    "if 'memory_total_gb' in system_info:\n",
    "    print(f\"💾 Memory: {system_info['memory_available_gb']:.1f}GB available / {system_info['memory_total_gb']:.1f}GB total\")\n",
    "    print(f\"🖥️ CPU: {system_info['cpu_cores']} cores\")\n",
    "\n",
    "print(f\"\\n📦 Package Installation: {report['installation_summary']['success_rate']}\")\n",
    "print(f\"🧪 Functionality Tests: {report['functionality_tests']['success_rate']}\")\n",
    "\n",
    "if report['ready_for_workshop']:\n",
    "    print(\"\\n🟢 STATUS: READY FOR WORKSHOP! 🎉\")\n",
    "    print(\"✅ Your environment is properly configured\")\n",
    "    print(\"✅ Core ML functionality verified\")\n",
    "    print(\"✅ You can proceed to Module 2: Predictive Model\")\n",
    "else:\n",
    "    print(\"\\n🟡 STATUS: PARTIALLY READY\")\n",
    "    print(\"⚠️ Some features may be limited\")\n",
    "    print(\"💡 Consider installing missing packages manually\")\n",
    "    print(\"📝 Check the failed tests above for details\")\n",
    "\n",
    "print(f\"\\n📊 Full report saved to: workshop_environment_report.json\")\n",
    "\n",
    "# Optional packages reminder\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"💡 OPTIONAL PACKAGES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"For advanced features, you can install these manually:\")\n",
    "for package in OPTIONAL_PACKAGES:\n",
    "    print(f\"  pip install {package}\")\n",
    "\n",
    "print(\"\\n🚀 Ready for Module 2: Predictive Model Development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Next Steps\n",
    "\n",
    "Your Python environment setup is complete! Here's what to do next:\n",
    "\n",
    "### ✅ If Status is \"READY FOR WORKSHOP\" (Green):\n",
    "1. **Continue to Module 2:** Start with predictive model development\n",
    "2. **Run verification notebook:** `1-environment/verify_environment.ipynb`\n",
    "3. **Download datasets:** `1-environment/download_datasets.ipynb`\n",
    "\n",
    "### ⚠️ If Status is \"PARTIALLY READY\" (Yellow):\n",
    "1. **Review failed packages:** Check which specific features are missing\n",
    "2. **Install manually:** Use the pip commands shown above for missing packages\n",
    "3. **Restart kernel:** After manual installations, restart and re-run verification\n",
    "4. **Continue anyway:** Most workshop features should still work\n",
    "\n",
    "### 🔧 Manual Installation Commands:\n",
    "```bash\n",
    "# If specific packages failed, try:\n",
    "pip install --no-cache-dir package_name\n",
    "pip install --user package_name\n",
    "pip install --force-reinstall package_name\n",
    "\n",
    "# For optional advanced features:\n",
    "pip install streamlit>=1.28.0\n",
    "pip install transformers>=4.36.0\n",
    "pip install torch>=2.1.0\n",
    "```\n",
    "\n",
    "### 📚 What You Now Have:\n",
    "- ✅ **Core ML:** scikit-learn, pandas, numpy\n",
    "- ✅ **Model Export:** ONNX conversion capabilities\n",
    "- ✅ **LLM Integration:** LangChain framework\n",
    "- ✅ **Visualization:** matplotlib, plotly, seaborn\n",
    "- ✅ **Web Interface:** Gradio for dashboards\n",
    "- ✅ **Monitoring:** System metrics collection\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for the next step?** 🚀  \n",
    "**Next:** [Module 2 - Predictive Model Development](../02-predictive-model.md)\n",
    "\n",
    "---\n",
    "\n",
    "*Workshop Progress: Module 1 Complete ✅*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
