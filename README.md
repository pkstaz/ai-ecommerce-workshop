# Deploy, Serve & Scale: OpenShift AI End-to-End Workshop
## Intelligent E-commerce Recommendation and Analysis System

<div align="center">

![OpenShift AI](https://img.shields.io/badge/OpenShift-AI-red?style=for-the-badge&logo=redhat)
![Workshop](https://img.shields.io/badge/Workshop-Hands--on-blue?style=for-the-badge)
![Duration](https://img.shields.io/badge/Duration-4%20hours-green?style=for-the-badge)

</div>

---

## ğŸŒ Language / Idioma

**[ğŸ‡ºğŸ‡¸ English Version](./docs/en/README.md)** - Complete workshop guide in English

**[ğŸ‡ªğŸ‡¸ VersiÃ³n en EspaÃ±ol](./docs/es/README.md)** - GuÃ­a completa del taller en espaÃ±ol

---

## ğŸ“‹ Quick Overview

This workshop provides hands-on experience with deploying, serving, and scaling AI models on OpenShift AI platform. You'll build an intelligent e-commerce system that combines predictive and generative AI models.

**Instructor:** Carlos Estay  
**Email:** cestay@redhat.com  
**GitHub:** [pkstaz](https://github.com/pkstaz)

---

## ğŸ¯ What You'll Learn

- Deploy predictive models using ONNX and OpenVINO
- Serve generative models with vLLM and Granite 3.1 8B
- Integrate models using LangChain framework
- Build interactive AI-powered dashboards
- Implement monitoring and optimization strategies

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    A[Jupyter Notebook] --> B[LangChain Integration]
    B --> C[Predictive Model<br/>Random Forest + OpenVINO]
    B --> D[Generative Model<br/>Granite 3.1 8B + vLLM]
    C --> E[Sales Forecasting]
    D --> F[Product Descriptions]
    E --> G[E-commerce Dashboard]
    F --> G
```

---

## ğŸ“š Module Structure

| Module | Topic | Duration | Description |
|--------|-------|----------|-------------|
| **1** | [Environment Setup](./docs/en/01-environment-setup.md) | 30 min | Configure OpenShift AI and prepare workspace |
| **2** | [Predictive Model](./docs/en/02-predictive-model.md) | 45 min | Deploy Random Forest with ONNX and OpenVINO |
| **3** | [Generative Model](./docs/en/03-generative-model.md) | 45 min | Serve Granite 3.1 8B using vLLM |
| **4** | [LangChain Integration](./docs/en/04-langchain-integration.md) | 45 min | Connect and orchestrate models |
| **5** | [Monitoring](./docs/en/05-monitoring.md) | 30 min | Implement monitoring and optimization |
| **6** | [Advanced MLOps](./docs/en/06-advanced-mlops.md) | 30 min | Production considerations and best practices |

---

## ğŸš€ Quick Start

### Prerequisites Checklist

- [ ] OpenShift cluster with OpenShift AI installed
- [ ] Access to Jupyter Hub
- [ ] Basic Python and ML knowledge
- [ ] Understanding of containerization concepts
- [ ] Familiarity with REST APIs

### Getting Started

1. **Choose your language:**
   - [ğŸ‡ºğŸ‡¸ Continue in English](./docs/en/README.md)
   - [ğŸ‡ªğŸ‡¸ Continuar en EspaÃ±ol](./docs/es/README.md)

2. **Follow the step-by-step modules** in your preferred language

3. **Access the code files** referenced in each module (provided separately)

---

## ğŸ“‚ Repository Structure

```
ai-ecommerce-workshop/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ en/                           # English documentation
â”‚   â”‚   â”œâ”€â”€ README.md                 # English workshop guide
â”‚   â”‚   â”œâ”€â”€ 01-environment-setup.md
â”‚   â”‚   â”œâ”€â”€ 02-predictive-model.md
â”‚   â”‚   â”œâ”€â”€ 03-generative-model.md
â”‚   â”‚   â”œâ”€â”€ 04-langchain-integration.md
â”‚   â”‚   â”œâ”€â”€ 05-monitoring.md
â”‚   â”‚   â””â”€â”€ 06-advanced-mlops.md
â”‚   â””â”€â”€ es/                           # Spanish documentation
â”‚       â”œâ”€â”€ README.md                 # Spanish workshop guide
â”‚       â”œâ”€â”€ 01-configuracion-entorno.md
â”‚       â”œâ”€â”€ 02-modelo-predictivo.md
â”‚       â”œâ”€â”€ 03-modelo-generativo.md
â”‚       â”œâ”€â”€ 04-integracion-langchain.md
â”‚       â”œâ”€â”€ 05-monitoreo.md
â”‚       â””â”€â”€ 06-mlops-avanzado.md
â”œâ”€â”€ 1-environment/                    # Module 1: Environment setup
â”‚   â”œâ”€â”€ download_datasets.ipynb
â”‚   â”œâ”€â”€ install_requirements.ipynb
â”‚   â”œâ”€â”€ verify_environment.ipynb
â”‚   â””â”€â”€ configs/
â”œâ”€â”€ 2-predictive-model/               # Module 2: Sales forecasting model
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_train_model.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_export_onnx.ipynb
â”‚   â”‚   â””â”€â”€ 05_validate_onnx.ipynb
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ serving-runtime.yaml
â”‚   â”‚   â”œâ”€â”€ inference-service.yaml
â”‚   â”‚   â””â”€â”€ test_deployment.ipynb
â”‚   â””â”€â”€ models/                       # Exported models
â”œâ”€â”€ 3-generative-model/               # Module 3: Granite 3.1 8B deployment
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_resource_planning.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_api_testing.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_performance_benchmark.ipynb
â”‚   â”‚   â””â”€â”€ 04_prompt_optimization.ipynb
â”‚   â””â”€â”€ deployment/
â”‚       â”œâ”€â”€ serving-runtime.yaml
â”‚       â”œâ”€â”€ inference-service.yaml
â”‚       â””â”€â”€ verify_deployment.ipynb
â”œâ”€â”€ 4-langchain-integration/          # Module 4: LangChain orchestration
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ 01_setup_langchain.ipynb
â”‚   â”‚   â”œâ”€â”€ 02_model_wrappers.ipynb
â”‚   â”‚   â”œâ”€â”€ 03_product_analysis_chain.ipynb
â”‚   â”‚   â”œâ”€â”€ 04_customer_insight_chain.ipynb
â”‚   â”‚   â”œâ”€â”€ 05_market_analysis_chain.ipynb
â”‚   â”‚   â”œâ”€â”€ 06_dashboard.ipynb
â”‚   â”‚   â””â”€â”€ 07_e2e_testing.ipynb
â”‚   â””â”€â”€ deployment/
â”‚       â””â”€â”€ deploy_dashboard.ipynb
â”œâ”€â”€ 5-monitoring-optimization/        # Module 5: Monitoring and optimization
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ model_monitoring_config.yaml
â”‚   â”‚   â”œâ”€â”€ custom_metrics.ipynb
â”‚   â”‚   â”œâ”€â”€ prometheus_alerts.yaml
â”‚   â”‚   â””â”€â”€ notification_config.yaml
â”‚   â””â”€â”€ optimization/
â”‚       â”œâ”€â”€ model_quantization.ipynb
â”‚       â”œâ”€â”€ caching_strategy.ipynb
â”‚       â””â”€â”€ autoscaling_config.yaml
â”œâ”€â”€ 6-advanced-mlops/                 # Module 6: Advanced MLOps practices
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ model_versioning.ipynb
â”‚   â”‚   â”œâ”€â”€ quality_gates.ipynb
â”‚   â”‚   â””â”€â”€ model_governance.ipynb
â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ ab_testing.yaml
â”‚   â”‚   â””â”€â”€ gitops_pipeline.yaml
â”‚   â””â”€â”€ security/
â”‚       â””â”€â”€ security_policies.yaml
â”œâ”€â”€ troubleshooting/                  # Debugging and troubleshooting
â”‚   â”œâ”€â”€ debug_onnx_conversion.ipynb
â”‚   â”œâ”€â”€ test_endpoints.ipynb
â”‚   â””â”€â”€ common_issues.md
â”œâ”€â”€ datasets/                         # Sample datasets (downloaded in module 1)
â”‚   â”œâ”€â”€ sales_historical_data.csv
â”‚   â”œâ”€â”€ product_catalog.csv
â”‚   â””â”€â”€ customer_behavior.csv
â””â”€â”€ assets/                           # Images and diagrams
    â”œâ”€â”€ architecture_diagram.png
    â””â”€â”€ workflow_diagrams/
```

---

## ğŸ¯ Learning Outcomes

After completing this workshop, you will be able to:

- âœ… Deploy production-ready ML models on OpenShift AI
- âœ… Optimize inference performance using ONNX and OpenVINO
- âœ… Serve large language models with high throughput using vLLM
- âœ… Build end-to-end AI applications with LangChain
- âœ… Implement monitoring and scaling strategies
- âœ… Apply MLOps best practices for production deployments

---

## ğŸ¤ Support and Feedback

**Instructor Contact:**
- **Name:** Carlos Estay
- **Email:** cestay@redhat.com
- **GitHub:** [pkstaz](https://github.com/pkstaz)

**For technical issues:**
- Create an issue in this repository
- Contact the instructor during workshop hours
- Check the troubleshooting sections in each module

---

## ğŸ“š Additional Resources

- [OpenShift AI Documentation](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed)
- [KServe Documentation](https://kserve.github.io/website/)
- [OpenVINO Documentation](https://docs.openvino.ai/)
- [vLLM Documentation](https://docs.vllm.ai/)
- [LangChain Documentation](https://python.langchain.com/)

---

**Â© 2025 Red Hat, Inc. - Workshop Material**