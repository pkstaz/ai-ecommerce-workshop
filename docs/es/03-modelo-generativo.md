# M√≥dulo 3: Modelo Generativo
## ü§ñ Granite 3.1 8B Instruct con Servicio vLLM

---

### üìç Navegaci√≥n
[‚¨ÖÔ∏è Anterior: Modelo Predictivo](02-modelo-predictivo.md) | [üè† Gu√≠a Principal](../README.md) | [‚û°Ô∏è Siguiente: Integraci√≥n LangChain](04-integracion-langchain.md)

---

**Duraci√≥n:** 45 minutos  
**Objetivo:** Desplegar y servir un modelo de lenguaje grande para generar descripciones de productos y recomendaciones.

---

## üéØ Resumen del M√≥dulo

En este m√≥dulo aprender√°s a:
- üîç **Comprender** las capacidades y casos de uso de Granite 3.1 8B
- üìä **Planificar** los requisitos de recursos para despliegue de LLM
- üöÄ **Desplegar** Granite 3.1 8B usando servicio vLLM
- ‚ö° **Optimizar** rendimiento y throughput
- üß™ **Probar** capacidades de generaci√≥n de texto
- üìù **Ingeniar** prompts para aplicaciones de e-commerce

---

## üß† Paso 3.1: Descripci√≥n de Granite 3.1 8B Instruct

### Capacidades del Modelo

**Granite 3.1 8B Instruct** es un modelo de lenguaje de grado empresarial dise√±ado para:

#### **Casos de Uso en E-commerce**
- **Descripciones de Productos** - Generar copy atractivo que aumenta conversiones
- **Recomendaciones Personalizadas** - Crear sugerencias dirigidas que mejoran engagement
- **An√°lisis de Clientes** - Sintetizar an√°lisis de comportamiento para decisiones basadas en datos
- **Soporte Conversacional** - Servicio al cliente inteligente que reduce costos de soporte
- **Generaci√≥n de Contenido** - Materiales de marketing y blogs que escalan la creaci√≥n

#### **Ventajas T√©cnicas**
- **Arquitectura Transformer** - Tecnolog√≠a de vanguardia para comprensi√≥n y generaci√≥n
- **Ajuste por Instrucciones** - Entrenado espec√≠ficamente para seguir instrucciones complejas
- **Contexto Extendido** - Capacidad de procesar hasta 4,096 tokens
- **Optimizaci√≥n de Razonamiento** - Excelente para tareas anal√≠ticas y de s√≠ntesis

### Especificaciones T√©cnicas

| Caracter√≠stica | Especificaci√≥n | Beneficio |
|----------------|----------------|-----------|
| **Par√°metros** | 8 mil millones | Balance entre capacidad y eficiencia |
| **Contexto M√°ximo** | 4,096 tokens | Procesamiento de documentos largos |
| **Precisi√≥n** | FP16/INT8 | Flexibilidad entre calidad y velocidad |
| **Memoria Base** | ~16GB (FP16) | Requisitos moderados de hardware |

### Beneficios Empresariales

‚úÖ **Soporte Red Hat** - Soporte empresarial y certificaci√≥n  
‚úÖ **Optimizado para Razonamiento** - Excelente para tareas anal√≠ticas  
‚úÖ **Alineado con Seguridad** - Outputs reducidos de contenido da√±ino  
‚úÖ **Licencia Comercial** - Licenciamiento claro para uso empresarial  
‚úÖ **Optimizado en Rendimiento** - Balance entre precisi√≥n y velocidad  

---

## üìä Paso 3.2: Planificaci√≥n de Recursos y Configuraci√≥n vLLM

### Entendiendo las Ventajas de vLLM

**vLLM (Very Large Language Model serving)** proporciona caracter√≠sticas avanzadas:

#### **Tecnolog√≠as de Optimizaci√≥n**
- **Continuous Batching** - Procesa m√∫ltiples requests de manera eficiente
- **PagedAttention** - Gesti√≥n optimizada de memoria para atenci√≥n
- **API Compatible con OpenAI** - Interfaz est√°ndar para f√°cil integraci√≥n
- **Aceleraci√≥n GPU** - Optimizaci√≥n de hardware para 10x m√°s velocidad

#### **Beneficios de Rendimiento**
| Caracter√≠stica | Beneficio | Impacto |
|----------------|-----------|---------|
| **Batching Continuo** | Procesa requests eficientemente | 2-3x mayor throughput |
| **PagedAttention** | Gesti√≥n optimizada de memoria | 2x m√°s usuarios concurrentes |
| **GPU Acceleration** | Optimizaci√≥n de hardware | 10x m√°s r√°pido que CPU |
| **API OpenAI** | Interfaz est√°ndar | Integraci√≥n simplificada |

### Planificaci√≥n de Recursos

El notebook `3-generative-model/notebooks/01_resource_planning.ipynb` calcular√° requisitos espec√≠ficos:

#### **Factores de Estimaci√≥n de Recursos**
- **Tama√±o del modelo y precisi√≥n** - FP16 vs INT8 afecta memoria requerida
- **Tama√±o de batch y longitud de secuencia** - Impacta memoria y throughput
- **Requisitos de memoria GPU** - C√°lculos espec√≠ficos para hardware
- **CPU y memoria del sistema** - Recursos complementarios necesarios
- **Almacenamiento** - Espacio para archivos de modelo y cache

#### **Configuraciones Recomendadas**

| Configuraci√≥n | Memoria GPU | CPU | RAM Sistema | Caso de Uso |
|---------------|-------------|-----|-------------|-------------|
| **M√≠nima** | 8GB | 4 cores | 16GB | Desarrollo/Pruebas |
| **Producci√≥n** | 16GB | 8 cores | 32GB | Cargas de trabajo productivas |
| **Alto Rendimiento** | 24GB+ | 16 cores | 64GB | Servicio de alto throughput |

#### **Evaluaci√≥n de Compatibilidad GPU**
El notebook evaluar√° compatibilidad con GPUs disponibles:
- **NVIDIA A100** (40GB/80GB) - √ìptima para todos los casos
- **NVIDIA V100** (32GB) - Buena para producci√≥n
- **NVIDIA RTX 4090** (24GB) - Buena para desarrollo avanzado
- **NVIDIA T4** (16GB) - M√≠nima con INT8

**‚úÖ Punto de Control:** Los requisitos de recursos est√°n calculados y la disponibilidad de GPU confirmada.

---

## üöÄ Paso 3.3: Despliegue del Modelo vLLM

### Preparar ServingRuntime vLLM

El archivo `3-generative-model/deployment/serving-runtime.yaml` define la configuraci√≥n:

#### **Componentes Clave del Runtime**
- **Imagen de contenedor** - vLLM optimizado con OpenAI API
- **Argumentos de comando** - Par√°metros espec√≠ficos para Granite 3.1 8B
- **Variables de entorno** - Tokens de acceso y configuraciones
- **Recursos de GPU** - Asignaci√≥n y l√≠mites de hardware

#### **Par√°metros Cr√≠ticos de Configuraci√≥n**

| Par√°metro | Valor | Prop√≥sito |
|-----------|-------|-----------|
| `tensor-parallel-size` | 1 | N√∫mero de GPUs para sharding del modelo |
| `gpu-memory-utilization` | 0.8 | Uso de memoria GPU (80%) |
| `max-model-len` | 4096 | Longitud m√°xima de secuencia |
| `served-model-name` | granite-3-1-8b | Identificador del modelo para API |

### Desplegar InferenceService

El archivo `3-generative-model/deployment/inference-service.yaml` especifica:

#### **Configuraci√≥n del Servicio**
- **Referencia al modelo** - Ubicaci√≥n en Hugging Face Hub
- **Runtime utilizado** - Conexi√≥n con vLLM ServingRuntime
- **Pol√≠tica de escalado** - Configuraci√≥n min/max replicas
- **Recursos asignados** - GPU, CPU y memoria

#### **Monitoreo del Despliegue**
El proceso de despliegue incluye:
- **Descarga del modelo** - Puede tomar 5-10 minutos inicialmente
- **Inicializaci√≥n vLLM** - Carga en memoria GPU
- **Validaci√≥n de salud** - Verificaci√≥n de endpoints
- **Estado de disponibilidad** - Confirmaci√≥n "Ready"

### Verificaci√≥n de Carga del Modelo

El notebook `3-generative-model/deployment/verify_deployment.ipynb` realizar√° verificaciones:

#### **Verificaciones de Despliegue**
- **Estado del InferenceService** - Confirmar estado "Ready"
- **Accesibilidad del endpoint API** - Pruebas de conectividad
- **Carga completa del modelo** - Validaci√≥n que est√° en memoria
- **Prueba b√°sica de generaci√≥n** - Test de funcionalidad
- **Validaci√≥n de formato de respuesta** - Estructura de outputs

**‚úÖ Punto de Control:** Granite 3.1 8B est√° desplegado y listo para servir requests.

---

## üß™ Paso 3.4: Pruebas de API y Benchmarking de Rendimiento

### Pruebas B√°sicas de API

El notebook `3-generative-model/notebooks/02_api_testing.ipynb` demostrar√°:

#### **Capacidades de Generaci√≥n**
- **Generaci√≥n b√°sica de texto** - Pruebas de funcionalidad core
- **Respuesta a instrucciones** - Validaci√≥n de capacidades de seguimiento
- **Generaci√≥n condicionada** - Outputs basados en prompts espec√≠ficos
- **Variabilidad creativa** - Ajuste de par√°metros de temperatura

#### **Optimizaci√≥n de Par√°metros de API**

| Par√°metro | Rango | Efecto | Recomendaci√≥n |
|-----------|-------|--------|---------------|
| `temperature` | 0.0-1.0 | Creatividad vs consistencia | 0.7 para descripciones |
| `top_p` | 0.1-1.0 | Diversidad de selecci√≥n de tokens | 0.9 para calidad |
| `max_tokens` | 50-500 | Longitud de respuesta | 150-200 para productos |
| `frequency_penalty` | 0.0-2.0 | Reducci√≥n de repetici√≥n | 0.1-0.3 |

#### **Casos de Uso Espec√≠ficos**
El notebook incluir√° ejemplos para:
- **Descripciones de productos** - Copy atractivo y persuasivo
- **Recomendaciones personalizadas** - Sugerencias basadas en perfil
- **An√°lisis de mercado** - S√≠ntesis de tendencias y datos
- **Contenido de marketing** - Materiales promocionales

### Benchmarking de Rendimiento

El notebook `3-generative-model/notebooks/03_performance_benchmark.ipynb` medir√°:

#### **M√©tricas de Rendimiento Clave**

| M√©trica | Descripci√≥n | Objetivo |
|---------|-------------|----------|
| **Latencia del Primer Token** | Tiempo hasta el primer token de respuesta | < 500ms |
| **Tokens por Segundo** | Throughput de generaci√≥n | > 50 TPS |
| **Requests Concurrentes** | Capacidad de procesamiento paralelo | > 10 concurrentes |
| **Utilizaci√≥n GPU** | Eficiencia de hardware | 70-90% |

#### **Resultados Esperados de Benchmark**
- **Latencia del Primer Token:** 200-400ms
- **Velocidad de Generaci√≥n:** 50-80 tokens/segundo
- **Usuarios Concurrentes:** 10-20 (dependiendo de GPU)
- **Uso de Memoria GPU:** 12-16GB

**‚úÖ Punto de Control:** Los benchmarks de rendimiento cumplen con requisitos de producci√≥n.

---

## üìù Paso 3.5: Ingenier√≠a de Prompts para E-commerce

### Plantillas de Prompts Especializadas

El notebook `3-generative-model/notebooks/04_prompt_optimization.ipynb` crear√° plantillas para:

#### **Generaci√≥n de Descripciones de Productos**
Las plantillas incluir√°n elementos estructurados para:
- **Informaci√≥n del producto** - Nombre, categor√≠a, caracter√≠sticas clave
- **Rango de precios** - Contexto de posicionamiento
- **Audiencia objetivo** - Segmentaci√≥n de clientes
- **Directrices de tono** - Profesional, casual, t√©cnico, etc.

#### **Recomendaciones Personalizadas**
Prompts que incorporen:
- **Perfil del cliente** - Historial de compras y preferencias
- **Contexto de navegaci√≥n** - Productos vistos y comportamiento
- **Restricciones de presupuesto** - Rangos de precio apropiados
- **Formato de output** - Estructura de recomendaciones

#### **An√°lisis de Mercado**
Plantillas para:
- **An√°lisis competitivo** - Comparaci√≥n de productos y posicionamiento
- **Identificaci√≥n de tendencias** - Patrones en datos de ventas
- **Oportunidades de crecimiento** - Gaps de mercado y nichos
- **Estrategias de pricing** - Recomendaciones de precios

### T√©cnicas Avanzadas de Prompting

#### **Few-Shot Learning**
Implementaci√≥n de ejemplos para asegurar:
- **Consistencia de formato** - Outputs estructurados predeciblemente
- **Calidad de contenido** - Ejemplos de alta calidad como referencia
- **Adherencia a guidelines** - Seguimiento de est√°ndares de marca

#### **Chain-of-Thought Prompting**
Para an√°lisis complejos que requieren:
- **Razonamiento paso a paso** - Desglose de an√°lisis complejos
- **Justificaci√≥n transparente** - Explicaci√≥n del proceso de pensamiento
- **Conclusiones fundamentadas** - Recomendaciones basadas en evidencia

#### **Prompt Templates Din√°micos**
Sistemas que permiten:
- **Personalizaci√≥n autom√°tica** - Ajuste basado en contexto
- **Escalabilidad** - Generaci√≥n masiva con calidad consistente
- **A/B testing** - Comparaci√≥n de diferentes enfoques de prompting

**‚úÖ Punto de Control:** Las plantillas de prompts est√°n optimizadas para casos de uso de e-commerce.

---

## üîß Gu√≠a de Soluci√≥n de Problemas

### Timeout de Carga del Modelo

**S√≠ntomas:** El modelo no se carga dentro del tiempo esperado

**Causas Comunes:**
- **Descarga lenta** - Conectividad limitada a Hugging Face Hub
- **Memoria insuficiente** - GPU no tiene capacidad para el modelo
- **Configuraci√≥n incorrecta** - Par√°metros de vLLM incompatibles

**Estrategias de Soluci√≥n:**
El notebook incluye verificaciones de conectividad y alternativas de configuraci√≥n para diferentes limitaciones de hardware.

### Problemas de Alta Latencia

**S√≠ntomas:** Tiempo de respuesta > 2 segundos

**Factores Contribuyentes:**
- **Configuraci√≥n sub√≥ptima** - Par√°metros de vLLM no optimizados
- **Recursos limitados** - CPU o GPU insuficientes
- **Concurrencia alta** - Demasiados requests simult√°neos

**Optimizaciones Disponibles:**
- **Ajuste de memoria GPU** - Incremento de utilizaci√≥n permitida
- **Optimizaci√≥n de batch** - Configuraci√≥n de procesamiento por lotes
- **Tuning de secuencias** - Ajuste de longitudes m√°ximas

### Errores de Memoria

**S√≠ntomas:** `CUDA out of memory` u errores similares

**Soluciones Progresivas:**
- **Cuantizaci√≥n INT8** - Reducci√≥n de precisi√≥n del modelo
- **Reducci√≥n de contexto** - Longitudes de secuencia m√°s cortas
- **Gesti√≥n conservadora** - Uso m√°s conservador de memoria GPU

### Optimizaci√≥n de Velocidad de Generaci√≥n

**S√≠ntomas:** < 20 tokens por segundo

**T√©cnicas de Optimizaci√≥n:**
- **Par√°metros de generaci√≥n** - Ajuste de max_tokens y early stopping
- **Configuraci√≥n de hardware** - Optimizaci√≥n de configuraciones vLLM
- **Prompt engineering** - Prompts m√°s eficientes que generan menos tokens

---

## üìä Resumen del M√≥dulo

### Lo Que Has Logrado

‚úÖ **Despliegue Exitoso del Modelo**
- Desplegado Granite 3.1 8B con servicio vLLM
- Configurado asignaci√≥n √≥ptima de recursos
- Logrado rendimiento listo para producci√≥n

‚úÖ **Optimizaci√≥n de Rendimiento**
- Medido m√©tricas clave de rendimiento
- Optimizado par√°metros de generaci√≥n
- Implementado manejo de requests concurrentes

‚úÖ **Integraci√≥n Lista para E-commerce**
- Desarrollado plantillas especializadas de prompts
- Creado generadores de descripciones de productos
- Construido sistemas de recomendaciones

‚úÖ **Preparaci√≥n para Producci√≥n**
- Implementado monitoreo y health checks
- Configurado pol√≠ticas de auto-scaling
- Validado compatibilidad de API

### Resultados Clave de Rendimiento

| M√©trica | Logro |
|---------|-------|
| **Tiempo de Despliegue** | ~8 minutos (incluyendo descarga del modelo) |
| **Latencia del Primer Token** | ~300ms promedio |
| **Velocidad de Generaci√≥n** | ~65 tokens/segundo |
| **Capacidad Concurrente** | 15+ requests paralelos |
| **Eficiencia GPU** | 75-85% eficiente |

---

## üöÄ Pr√≥ximos Pasos

¬°Tu modelo de IA generativa est√° ahora sirviendo generaci√≥n de texto de alta calidad! En el siguiente m√≥dulo aprender√°s:

1. **Integrar con LangChain** - Framework unificado para orquestaci√≥n de IA
2. **Conectar ambos modelos** - Combinar capacidades predictivas y generativas
3. **Construir chains de IA** - Crear workflows sofisticados
4. **Desarrollar dashboard** - Interfaz de usuario interactiva
5. **Probar extremo a extremo** - Validaci√≥n completa del sistema

¬°La integraci√≥n permitir√° casos de uso poderosos como predecir ventas Y generar explicaciones, o crear recomendaciones de productos con descripciones atractivas!

---

### üìÅ Archivos Referenciados en Este M√≥dulo
- `3-generative-model/notebooks/01_resource_planning.ipynb`
- `3-generative-model/notebooks/02_api_testing.ipynb`
- `3-generative-model/notebooks/03_performance_benchmark.ipynb`
- `3-generative-model/notebooks/04_prompt_optimization.ipynb`
- `3-generative-model/deployment/serving-runtime.yaml`
- `3-generative-model/deployment/inference-service.yaml`
- `3-generative-model/deployment/verify_deployment.ipynb`

---

### üìç Navegaci√≥n
[‚¨ÖÔ∏è Anterior: Modelo Predictivo](02-modelo-predictivo.md) | [üè† Gu√≠a Principal](../README.md) | [‚û°Ô∏è Siguiente: Integraci√≥n LangChain](04-integracion-langchain.md)

---

*¬°Contin√∫a al M√≥dulo 4 para orquestar ambos modelos en un sistema de IA unificado!*