# M√≥dulo 1: Configuraci√≥n del Entorno
## üõ†Ô∏è Preparando tu Espacio de Trabajo en OpenShift AI

---

### üìç Navegaci√≥n
[‚¨ÖÔ∏è Volver a la Gu√≠a Principal](../README.md) | [‚û°Ô∏è Siguiente: Modelo Predictivo](02-modelo-predictivo.md)

---

**Duraci√≥n:** 30 minutos  
**Objetivo:** Configurar un entorno de desarrollo completo para el despliegue de modelos de IA.

---

## üéØ Resumen del M√≥dulo

En este m√≥dulo aprender√°s a:
- ‚úÖ Verificar la instalaci√≥n de OpenShift AI y sus componentes
- ‚úÖ Crear y configurar un Proyecto de Ciencia de Datos
- ‚úÖ Configurar Jupyter Workbench con los recursos necesarios
- ‚úÖ Descargar datasets y instalar dependencias
- ‚úÖ Validar la configuraci√≥n completa del entorno

---

## üîç Paso 1.1: Verificar Instalaci√≥n de OpenShift AI

### Acceso al Dashboard de OpenShift AI

**OpenShift AI** es una plataforma integral que proporciona herramientas para el ciclo completo de Machine Learning. Incluye componentes esenciales como:

- **Proyectos de Ciencia de Datos** - Espacios de trabajo organizados para equipos de ML
- **Jupyter Hub** - Entornos de desarrollo interactivos
- **Model Serving** - Despliegue de modelos con KServe
- **Model Registry** - Gesti√≥n de versiones de modelos

### Verificaci√≥n de Componentes

Antes de comenzar, es importante confirmar que todos los componentes est√°n disponibles y funcionando correctamente. Esto incluye verificar:

1. **Operadores instalados** - Los operadores de OpenShift AI deben estar activos
2. **Recursos del cluster** - Suficiente CPU, memoria y almacenamiento
3. **Acceso a GPU** - Si est√° disponible para modelos generativos
4. **Conectividad de red** - Para descargar modelos y datasets

**‚úÖ Punto de Control:** Todos los componentes de OpenShift AI est√°n disponibles y el cluster tiene recursos suficientes.

---

## üèóÔ∏è Paso 1.2: Crear Proyecto de Ciencia de Datos

### Configuraci√≥n del Proyecto

Un **Proyecto de Ciencia de Datos** en OpenShift AI proporciona:
- **Aislamiento de recursos** - Separaci√≥n l√≥gica entre proyectos
- **Gesti√≥n de permisos** - Control de acceso basado en roles
- **Organizaci√≥n de workloads** - Agrupaci√≥n de notebooks, modelos y datos
- **Pol√≠ticas de red** - Seguridad y comunicaci√≥n entre servicios

### Detalles de Configuraci√≥n

Para el workshop, crearemos un proyecto llamado `ecommerce-ai-workshop` que incluir√°:
- **Configuraci√≥n de cuotas** - L√≠mites de recursos si los requiere el administrador
- **Pol√≠ticas de red** - Reglas de comunicaci√≥n entre servicios
- **Gesti√≥n de usuarios** - Permisos para miembros del equipo

El proyecto servir√° como contenedor para todos los recursos del taller, incluyendo notebooks, modelos desplegados, y servicios de monitoreo.

**‚úÖ Punto de Control:** El proyecto est√° creado y configurado correctamente.

---

## üíª Paso 1.3: Configurar Jupyter Workbench

### Arquitectura del Workbench

**Jupyter Workbench** es el entorno principal de desarrollo que proporciona:
- **Jupyter Lab** - Interfaz web interactiva para desarrollo
- **Kernels preconfigurados** - Entornos Python con librer√≠as de ML
- **Almacenamiento persistente** - Conservaci√≥n de trabajo entre sesiones
- **Recursos escalables** - CPU, memoria y GPU seg√∫n necesidades

### Configuraci√≥n de Recursos

Para el workshop, configuraremos un workbench con:

| Recurso | Valor | Justificaci√≥n |
|---------|-------|---------------|
| **CPU** | 4 cores | Procesamiento de datos y entrenamiento |
| **Memoria** | 8GB RAM | Carga de datasets y modelos |
| **Almacenamiento** | 20GB | Notebooks, datos y modelos exportados |
| **Imagen** | Standard Data Science | Librer√≠as ML preinstaladas |

### Variables de Entorno

Se configurar√°n variables clave para el workshop:
- **PYTHONPATH** - Rutas de m√≥dulos Python
- **MODEL_ENDPOINT_URL** - URLs de servicios de modelos
- **WORKSHOP_PATH** - Directorio base del taller

**‚úÖ Punto de Control:** Jupyter workbench est√° ejecut√°ndose y es accesible.

---

## üìä Paso 1.4: Preparar Materiales del Taller

### Descarga de Datasets

El notebook `1-environment/download_datasets.ipynb` realizar√° la descarga y validaci√≥n de tres datasets principales:

#### **Dataset de Ventas Hist√≥ricas**
- **Contenido:** Transacciones de ventas con patrones temporales
- **Tama√±o:** ~50MB con 10,000+ registros
- **Caracter√≠sticas:** Fechas, productos, cantidades, precios, categor√≠as
- **Uso:** Entrenamiento del modelo predictivo de pron√≥stico de ventas

#### **Cat√°logo de Productos**
- **Contenido:** Metadatos y categor√≠as de productos
- **Tama√±o:** ~5MB con 1,000+ productos
- **Caracter√≠sticas:** IDs, nombres, descripciones, categor√≠as, precios
- **Uso:** Generaci√≥n de descripciones y an√°lisis de productos

#### **Datos de Comportamiento del Cliente**
- **Contenido:** Interacciones y datos de comportamiento de usuarios
- **Tama√±o:** ~20MB con 5,000+ registros
- **Caracter√≠sticas:** Patrones de navegaci√≥n, preferencias, historial
- **Uso:** Recomendaciones personalizadas y an√°lisis de clientes

### Instalaci√≥n de Dependencias

El notebook `1-environment/install_requirements.ipynb` instalar√° las librer√≠as esenciales:

#### **Librer√≠as de Machine Learning**
- **scikit-learn** - Algoritmos de aprendizaje autom√°tico
- **pandas/numpy** - Manipulaci√≥n y an√°lisis de datos
- **matplotlib/plotly** - Visualizaci√≥n de datos

#### **Librer√≠as de Exportaci√≥n y Despliegue**
- **onnx/skl2onnx** - Conversi√≥n de modelos a formato ONNX
- **onnxruntime** - Ejecuci√≥n optimizada de modelos ONNX

#### **Librer√≠as de Orquestaci√≥n e Integraci√≥n**
- **langchain** - Framework de orquestaci√≥n de LLM
- **openai** - Cliente para APIs compatibles con OpenAI
- **requests** - Cliente HTTP para comunicaci√≥n con APIs

#### **Librer√≠as de Interface y Dashboard**
- **gradio** - Creaci√≥n de interfaces web interactivas
- **streamlit** - Alternativa para dashboards
- **ipywidgets** - Widgets interactivos para Jupyter

### Validaci√≥n del Entorno

El notebook `1-environment/verify_environment.ipynb` realizar√° verificaciones comprensivas:

#### **Verificaci√≥n de Librer√≠as**
- Importaci√≥n exitosa de todas las dependencias
- Verificaci√≥n de versiones compatibles
- Pruebas b√°sicas de funcionalidad

#### **Verificaci√≥n de Datasets**
- Integridad de archivos descargados
- Validaci√≥n de schemas de datos
- An√°lisis de calidad de datos b√°sico

#### **Verificaci√≥n de Recursos**
- Disponibilidad de memoria RAM
- Espacio en disco disponible
- Acceso a CPU y GPU (si aplica)

**‚úÖ Punto de Control:** Todas las librer√≠as est√°n instaladas y los datasets son accesibles.

---

## üîß Soluci√≥n de Problemas Comunes

### Problema 1: Workbench No Inicia

**S√≠ntomas:** El workbench se queda en estado "Starting" o "Error"

**Diagn√≥stico:**
El problema usualmente se debe a recursos insuficientes o problemas de conectividad. Es importante revisar los logs del pod y los eventos del namespace.

**Soluciones:**
- Verificar que hay recursos suficientes en el cluster
- Revisar pol√≠ticas de pull de im√°genes
- Validar claims de vol√∫menes persistentes
- Reiniciar el workbench si es necesario

### Problema 2: Fallos en Descarga de Datasets

**S√≠ntomas:** Errores de red o descargas incompletas

**Causa Com√∫n:**
Los problemas de descarga pueden deberse a restricciones de red, proxies corporativos, o problemas temporales de conectividad.

**Enfoque de Soluci√≥n:**
El notebook incluye funciones de verificaci√≥n de conectividad y mecanismos de reintento. Tambi√©n proporciona checksums para validar la integridad de los datos descargados.

### Problema 3: Conflictos de Paquetes

**S√≠ntomas:** Errores de resoluci√≥n de dependencias o fallos en importaciones

**Estrategia de Resoluci√≥n:**
El notebook utiliza un enfoque sistem√°tico para la instalaci√≥n, incluyendo limpieza de cache y reinstalaci√≥n forzada cuando es necesario. Tambi√©n considera el uso de conda como alternativa a pip.

---

## üìù Resumen de Configuraci√≥n del Entorno

Despu√©s de completar este m√≥dulo, tu entorno tendr√°:

### ‚úÖ **Infraestructura Lista**
- Proyecto OpenShift AI: `ecommerce-ai-workshop`
- Jupyter workbench: `workshop-notebook` con recursos adecuados
- Almacenamiento persistente: 20GB montado y accesible

### ‚úÖ **Datos Disponibles**
- Datos hist√≥ricos de ventas: 10,000+ transacciones
- Cat√°logo de productos: 1,000+ productos con metadatos
- Comportamiento de clientes: 5,000+ registros de interacci√≥n

### ‚úÖ **Entorno de Desarrollo**
- Todas las librer√≠as Python requeridas instaladas
- Variables de entorno configuradas
- Datasets validados y accesibles

### ‚úÖ **Verificaci√≥n Completa**
- Recursos del sistema confirmados como adecuados
- Importaciones de librer√≠as exitosas
- Listo para desarrollo de modelos

---

## üöÄ Pr√≥ximos Pasos

¬°Tu entorno est√° ahora listo para el desarrollo de modelos de IA! En el siguiente m√≥dulo aprender√°s:

1. **Explorar el dataset de ventas** y entender patrones de negocio
2. **Ingeniar caracter√≠sticas** para modelado predictivo
3. **Entrenar un modelo Random Forest** para pron√≥stico de ventas
4. **Exportar el modelo a formato ONNX** para servicio optimizado
5. **Desplegar con OpenVINO** para inferencia de alto rendimiento

---

### üìÅ Archivos Referenciados en Este M√≥dulo
- `1-environment/download_datasets.ipynb`
- `1-environment/install_requirements.ipynb`
- `1-environment/verify_environment.ipynb`

---

### üìç Navegaci√≥n
[‚¨ÖÔ∏è Volver a la Gu√≠a Principal](../README.md) | [‚û°Ô∏è Siguiente: Modelo Predictivo](02-modelo-predictivo.md)

---

*¬°Contin√∫a al M√≥dulo 2 para comenzar a construir tu primer modelo de IA para predicci√≥n de ventas!*